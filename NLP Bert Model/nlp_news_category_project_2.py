# -*- coding: utf-8 -*-
"""NLP News Category Project-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jRorK0yvyqPKKSigBXnFn_6MMEOHtNkw
"""

#Åimdi haber kategori sÄ±nÄ±flandÄ±rmada bir Ã¶nceki Ã¶rnekte TF-IDF yÃ¶ntemiyle Ã§Ã¶zmeye
#Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z sÄ±nÄ±flandÄ±rma iÅŸlemindeki problemi BERT modeli ile Ã§Ã¶zmeye Ã§alÄ±ÅŸalÄ±m


#klasik yÃ¶ntem kelime bazlÄ± cÃ¼mlelere baktÄ±ÄŸÄ± iÃ§in  setteki sÄ±nÄ±flandÄ±rmayÄ± doÄŸru
#yapsa da daha sonra girilen girdideki kelimeler eÄŸitim setinde az geÃ§tiyse yanlÄ±ÅŸ
#sÄ±nÄ±flandÄ±rabiliyordu. Bunun sebebi cÃ¼mle bazlÄ± deÄŸil kelime bazlÄ±
#bakmasÄ±ydÄ± bu durumu BERT ile Ã§Ã¶zebiliriz.
"""
BERT, Google tarafÄ±ndan geliÅŸtirilen ve metnin baÄŸlamÄ±nÄ± anlamaya odaklanan
 bir derin Ã¶ÄŸrenme modelidir."Bidirectional" yani Ã§ift yÃ¶nlÃ¼ Ã§alÄ±ÅŸÄ±r â†’ cÃ¼mledeki
 bir kelimenin hem Ã¶ncesine hem sonrasÄ±na bakarak anlam Ã§Ä±karÄ±r.

"""


"""
| Ã–zellik             | TF-IDF                     | BERT                        |
| ------------------- | -------------------------- | --------------------------- |
| Ã‡alÄ±ÅŸma mantÄ±ÄŸÄ±     | Kelime frekansÄ±na bakar    | Anlama, baÄŸlama bakar       |
| BaÄŸlam bilgisi      | âŒ Yok                      | âœ… Var                       |
| Anlam Ã§Ã¶zÃ¼mÃ¼        | âŒ Yapamaz                  | âœ… Yapar                     |
| â€œTransferâ€ kelimesi | Spor mu? SaÄŸlÄ±k mÄ±? Bilmez | CÃ¼mledeki yerine gÃ¶re anlar |
| Yeni cÃ¼mleler       | ÅaÅŸÄ±rabilir                | Genelde doÄŸru sÄ±nÄ±flandÄ±rÄ±r |


BERT Ne Ã–ÄŸrenir?
Kelimelerin sadece kendisini deÄŸil, Ã§evresindeki anlamÄ±

â€œbankâ€ kelimesinin â€œnehrin kenarÄ±â€ mÄ±, â€œpara kurumuâ€ mu olduÄŸunu, cÃ¼mleye gÃ¶re anlar.

Ã–rneÄŸin:

â€œBankta oturuyorumâ€ â†’ oturulan yer

â€œBank kredi verdiâ€ â†’ finans kurumu
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df = pd.read_csv("TurkishHeadlines.csv")
df.head()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


df.columns = ['haber', 'etiket']
#sÃ¼tun adlarÄ±nÄ± kÃ¼Ã§Ã¼ltme sadeleÅŸtirme

label_encode= LabelEncoder()
df['label']=label_encode.fit_transform(df['etiket'])

#etiketleri sayÄ±sal deÄŸerlere dÃ¶Ã¼ÅŸtÃ¼rme


num_labels = df['label'].nunique()
print(f"SÄ±nÄ±f SayÄ±sÄ±: {num_labels}")
print(label_encode.classes_)
#SÄ±nÄ±f bilgisi

train_texts, test_texts, train_labels, test_labels=train_test_split(
    df['haber'].tolist(),df['label'].tolist(),
    test_size=0.2,random_state=42, stratify=df['label']

)

#%80'e %20 eÄŸitim test verisi ayrÄ±mÄ± yapÄ±ldÄ±

#Hugging Faze Tokenizer ile metinleri modele hazÄ±rlama

!pip install transformers --quiet

from transformers import BertTokenizer

tokenizer=BertTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
#TÃ¼rkÃ§e BERT tokenizer yÃ¼kleme

train_encodings= tokenizer(
    train_texts, truncation=True, padding=True, max_length=64

    )#eÄŸitim ve test metinlerini tokenize etme


test_encodings = tokenizer(
    test_texts, truncation=True, padding=True, max_length=64
)

"""
| Parametre         | Ne iÅŸe yarar?                                          |
| ----------------- | ------------------------------------------------------ |
| `truncation=True` | Uzun cÃ¼mleleri keser (maksimum 64 token alÄ±r)          |
| `padding=True`    | KÄ±sa cÃ¼mlelerin uzunluÄŸunu eÅŸitler (64'e tamamlar)     |
| `max_length=64`   | Maksimum token sayÄ±sÄ± (haber baÅŸlÄ±klarÄ± iÃ§in idealdir) |

"""

#Tesnor FormatÄ±na Ã§evirme Dataset oluÅŸturma

import torch

from torch.utils.data import Dataset

class NewDataset(Dataset):

  def __init__(self,encodings,labels):
    self.encodings=encodings
    self.labels=labels


  def __len__(self):
    return len(self.labels)

  def __getitem__(self,idx):

    item={key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
    item["labels"] = torch.tensor(self.labels[idx])
    return item


train_dataset=NewDataset(train_encodings,train_labels)
test_dataset=NewDataset(test_encodings, test_labels)

#Model YÃ¼kleme

from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained(
    "dbmdz/bert-base-turkish-cased",
    num_labels=7
)

!pip install --upgrade transformers
!pip install -U transformers

import os
os.environ["WANDB_DISABLED"] = "true"

#Trainer ve EÄŸitim


from transformers import Trainer,TrainingArguments


training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    logging_dir="./logs",
    logging_steps=10
)



trainer=Trainer(

   model=model,
   args=training_args,
   train_dataset=train_dataset,
   eval_dataset=test_dataset,
)

trainer.train()

trainer.save_model("bert_modelim")  # modeli kaydet
tokenizer.save_pretrained("bert_modelim")  # tokenizer'Ä± da kaydet

from transformers import BertForSequenceClassification, BertTokenizerFast
import torch

#model ve tokenizer Ä± yÃ¼kleme
model = BertForSequenceClassification.from_pretrained("bert_modelim")
tokenizer = BertTokenizer.from_pretrained("bert_modelim")
model.eval()  #tahmin moduna alma

#YENÄ° GÄ°RDÄ°LERLE TAHMÄ°N

def bert_tahmin(metin):
  inputs = tokenizer(metin, return_tensors="pt",truncation=True, padding=True)
  with torch.no_grad():
    outputs = model(**inputs)

  logits = outputs.logits
  tahmin=torch.argmax(logits,dim=1).item()

  return tahmin # 0 veya 1


etiket_map = {
    0: "Ekonomi",
    1: "Magazin",
    2: "SaÄŸlÄ±k",
    3: "Siyaset",
    4: "Spor",
    5: "Teknoloji",
    6: "YaÅŸam"
}#Ã¶rnek
#etikerleri eÅŸleÅŸtirme

metin="FenerbahÃ§e trasnfer bombasÄ± patlattÄ±"

print("Kategori:", etiket_map[bert_tahmin(metin)])

def kullanicidan_haber_kategorisi_al():
    while True:
        baslik = input("Haber baÅŸlÄ±ÄŸÄ± girin (Ã§Ä±kmak iÃ§in q): ")
        if baslik.lower() == "q":
            print("Ã‡Ä±kÄ±lÄ±yor...")
            break
        inputs = tokenizer(baslik, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
        tahmin_id = torch.argmax(outputs.logits, dim=1).item()
        kategori = etiket_map[tahmin_id]
        print(f"ğŸ“¢ Tahmin edilen kategori: {kategori}\n")

kullanicidan_haber_kategorisi_al()

!zip -r bert_modelim.zip bert_modelim  #modeli zip oalrak kaydetme

from google.colab import files
files.download("bert_modelim.zip")
#zipi indirme