# -*- coding: utf-8 -*-
"""NLP News Category Project-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jRorK0yvyqPKKSigBXnFn_6MMEOHtNkw
"""

#Şimdi haber kategori sınıflandırmada bir önceki örnekte TF-IDF yöntemiyle çözmeye
#çalıştığımız sınıflandırma işlemindeki problemi BERT modeli ile çözmeye çalışalım


#klasik yöntem kelime bazlı cümlelere baktığı için  setteki sınıflandırmayı doğru
#yapsa da daha sonra girilen girdideki kelimeler eğitim setinde az geçtiyse yanlış
#sınıflandırabiliyordu. Bunun sebebi cümle bazlı değil kelime bazlı
#bakmasıydı bu durumu BERT ile çözebiliriz.
"""
BERT, Google tarafından geliştirilen ve metnin bağlamını anlamaya odaklanan
 bir derin öğrenme modelidir."Bidirectional" yani çift yönlü çalışır → cümledeki
 bir kelimenin hem öncesine hem sonrasına bakarak anlam çıkarır.

"""


"""
| Özellik             | TF-IDF                     | BERT                        |
| ------------------- | -------------------------- | --------------------------- |
| Çalışma mantığı     | Kelime frekansına bakar    | Anlama, bağlama bakar       |
| Bağlam bilgisi      | ❌ Yok                      | ✅ Var                       |
| Anlam çözümü        | ❌ Yapamaz                  | ✅ Yapar                     |
| “Transfer” kelimesi | Spor mu? Sağlık mı? Bilmez | Cümledeki yerine göre anlar |
| Yeni cümleler       | Şaşırabilir                | Genelde doğru sınıflandırır |


BERT Ne Öğrenir?
Kelimelerin sadece kendisini değil, çevresindeki anlamı

“bank” kelimesinin “nehrin kenarı” mı, “para kurumu” mu olduğunu, cümleye göre anlar.

Örneğin:

“Bankta oturuyorum” → oturulan yer

“Bank kredi verdi” → finans kurumu
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df = pd.read_csv("TurkishHeadlines.csv")
df.head()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


df.columns = ['haber', 'etiket']
#sütun adlarını küçültme sadeleştirme

label_encode= LabelEncoder()
df['label']=label_encode.fit_transform(df['etiket'])

#etiketleri sayısal değerlere döüştürme


num_labels = df['label'].nunique()
print(f"Sınıf Sayısı: {num_labels}")
print(label_encode.classes_)
#Sınıf bilgisi

train_texts, test_texts, train_labels, test_labels=train_test_split(
    df['haber'].tolist(),df['label'].tolist(),
    test_size=0.2,random_state=42, stratify=df['label']

)

#%80'e %20 eğitim test verisi ayrımı yapıldı

#Hugging Faze Tokenizer ile metinleri modele hazırlama

!pip install transformers --quiet

from transformers import BertTokenizer

tokenizer=BertTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
#Türkçe BERT tokenizer yükleme

train_encodings= tokenizer(
    train_texts, truncation=True, padding=True, max_length=64

    )#eğitim ve test metinlerini tokenize etme


test_encodings = tokenizer(
    test_texts, truncation=True, padding=True, max_length=64
)

"""
| Parametre         | Ne işe yarar?                                          |
| ----------------- | ------------------------------------------------------ |
| `truncation=True` | Uzun cümleleri keser (maksimum 64 token alır)          |
| `padding=True`    | Kısa cümlelerin uzunluğunu eşitler (64'e tamamlar)     |
| `max_length=64`   | Maksimum token sayısı (haber başlıkları için idealdir) |

"""

#Tesnor Formatına çevirme Dataset oluşturma

import torch

from torch.utils.data import Dataset

class NewDataset(Dataset):

  def __init__(self,encodings,labels):
    self.encodings=encodings
    self.labels=labels


  def __len__(self):
    return len(self.labels)

  def __getitem__(self,idx):

    item={key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
    item["labels"] = torch.tensor(self.labels[idx])
    return item


train_dataset=NewDataset(train_encodings,train_labels)
test_dataset=NewDataset(test_encodings, test_labels)

#Model Yükleme

from transformers import BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained(
    "dbmdz/bert-base-turkish-cased",
    num_labels=7
)

!pip install --upgrade transformers
!pip install -U transformers

import os
os.environ["WANDB_DISABLED"] = "true"

#Trainer ve Eğitim


from transformers import Trainer,TrainingArguments


training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    logging_dir="./logs",
    logging_steps=10
)



trainer=Trainer(

   model=model,
   args=training_args,
   train_dataset=train_dataset,
   eval_dataset=test_dataset,
)

trainer.train()

trainer.save_model("bert_modelim")  # modeli kaydet
tokenizer.save_pretrained("bert_modelim")  # tokenizer'ı da kaydet

from transformers import BertForSequenceClassification, BertTokenizerFast
import torch

#model ve tokenizer ı yükleme
model = BertForSequenceClassification.from_pretrained("bert_modelim")
tokenizer = BertTokenizer.from_pretrained("bert_modelim")
model.eval()  #tahmin moduna alma

#YENİ GİRDİLERLE TAHMİN

def bert_tahmin(metin):
  inputs = tokenizer(metin, return_tensors="pt",truncation=True, padding=True)
  with torch.no_grad():
    outputs = model(**inputs)

  logits = outputs.logits
  tahmin=torch.argmax(logits,dim=1).item()

  return tahmin # 0 veya 1


etiket_map = {
    0: "Ekonomi",
    1: "Magazin",
    2: "Sağlık",
    3: "Siyaset",
    4: "Spor",
    5: "Teknoloji",
    6: "Yaşam"
}#örnek
#etikerleri eşleştirme

metin="Fenerbahçe trasnfer bombası patlattı"

print("Kategori:", etiket_map[bert_tahmin(metin)])

def kullanicidan_haber_kategorisi_al():
    while True:
        baslik = input("Haber başlığı girin (çıkmak için q): ")
        if baslik.lower() == "q":
            print("Çıkılıyor...")
            break
        inputs = tokenizer(baslik, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = model(**inputs)
        tahmin_id = torch.argmax(outputs.logits, dim=1).item()
        kategori = etiket_map[tahmin_id]
        print(f"📢 Tahmin edilen kategori: {kategori}\n")

kullanicidan_haber_kategorisi_al()

!zip -r bert_modelim.zip bert_modelim  #modeli zip oalrak kaydetme

from google.colab import files
files.download("bert_modelim.zip")
#zipi indirme