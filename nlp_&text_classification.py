# -*- coding: utf-8 -*-
"""NLP &Text Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iri0a9MB6ZiCHG3EVLPnGTLQ4cxVComJ
"""

#NLP NEDİR?

"""
Doğal Dil İşleme(Natural Language Processing) bilgisayarların insan dilini
anlaması ve yorumlaması için kullnılan yöntem ve algoritmalar bütünüdür.

-->Bir yorumu  pozitif/negatif diye sınıflandırmak
-->Bif haberi kategoriye(spor,ekonomi,teknoloji)ayırmak
-->Arama motorlarının anahtar eklimesi anlaması

Bu işlem için metin veri önce sayısal hale getirilmelidir.

"""

#CountVectorizer(Kelime Sayma Yönetmi)

"""
Her metni kelimelerin sayısına göre vektör ile temsil etmektir.

İşleyiş:
    --->Tim metinlerde geçen benzersiz kelimelerden bir sözlük oluşturur.
    --->Her metin için bu kelimelerden kaç kez geçtiğini sayar.

Örneğin :
    Metinler=["Bugün hava güzel","Hava çok güzel"]

    Kelime Sözlüğü=["Bugün","hava","güzel","çok]

    Vektörler:
        1. cümle: [1,1,1,0]
        2.cümle:  [0,1,1,1]

"""

#Python Kullanımı

#from sklearn.feature_extraction.text import CounVectorizer
#cv=CountVectorizer()
#X=cv.fit_transform(metinler)

#TfidVectorizer(TF-IDF)

"""
Çok tekrar eden ama anlam taşımayan kelimelerin etkisiniz azaltmak.

TF(Term Frequency):Kelimenin metinde geçme oranıdır.

IDF(Inverse Documant Frequency):Kelimenin az dökümanda geçiyorsa değerli
olduğunu belirtir

Öreneiğin:

"ve","de","ile" gibi kelimeler her metinde geçmektedir.TD-IDF bu kelimelerin
ağırlıklarını düşürür

"""

#Python Kullanımı

#from sklearn.feature_extraction.text import TdifVectorizer
#tfid=TfidVectorizer()
#X=tfidf.fit_transform(metinler)

#Stopwords

"""
Anlam taşımayan kelimelerdir("ve","bir","da","çok","ama")

nltk kütüphanesi Türkçe liste sağlar

Metinleri temizlerken bu kelimeler kaldırılır.

"""

#Lemmatization&Stemming

"""
-->Lemmatizitaion: Kelimelerin szölükteki kökünü bulur("koşuyor"-->"koşmak")

-->Stemming : Kelimelerin sözlükteki kökünü bulur ancak biraz daha kaba ve
nettir.("koşuyor"-->"koş")

"""

#Naive Bayes Sınıflandırıcı

"""
Metin sınıflandırmada en çok kullanılan algoritmalardan biridir.

Bayes Teoremine dayanır

-->Bir kelimenin belirli bir sınıfta geçme olasılığını hesaplar

Pozitif/negatif yorum gibi iki sınıf veya çoklu kategori problemleri için
uygundur.

"""

#Python Kullanımı

#from sklearn.native_bayes import MultinomialNB

#model=MultinomialNB()

#model.fit(X_train,y_train)

#WorldCloud

"""
Metindeki kelimelerin frekansını görsel olarak bulut şeklinde gösterir

worldcloud kütüphanesi kullanılmaktadır.

"""

#Python Kullanımı

#from wordlcloud import WordlCloud

#WorldCloud().generate("metin verisi")

#Temel bilgileri tekra ettiğimize göre pratik yapmaya geçebiliriz.

#kenid bir kaç cümlemizden aşamaları örnekleyeceğiz

from sklearn.feature_extraction.text import CountVectorizer
#kelimeleri vektörel olarak tanımlayabilmek için

import pandas as pd
#Çıktıları tablo olarak gösterebilmek için

#Cümle Listesi

metinler =[

    "Bugün hava çok güzel",
    "Yarın yağmur yağacak",
    "Hava serin ama güzel",
    "Bugün hava yağmurlu",
    "Güzel bir gün"
]

cv=CountVectorizer()
#CountVectorizer nesnesi oluşturma


X = cv.fit_transform(metinler)
#fit_transform ile

"""
fit tüm metinlerin kelime sözlüğünü çıkarır

transform ise her metni kelime frekans vektörüne dönüştürür
"""

df=pd.DataFrame(X.toarray(),columns=cv.get_feature_names_out())
#çıkan X matrisi sparse matrix (seyrek matris) formatındadir
#bunu tabloya(DataFrame) dönüştürüp okunulabilir hale getirilmesi

print(df)

"""
TF-IDF yöntemi, şu mantığı kullanır:

"Bir kelime birçok dokümanda geçiyorsa önemsizdir, ama yalnızca bazı dokümanlarda
geçiyorsa ayırıcıdır."

"""

#TF-IDF ile Vektörelleştirme

from sklearn.feature_extraction.text import TfidfVectorizer

#cümlelerin tanımlanması

metinler = [
    "Bugün hava çok güzel",
    "Yarın yağmur yağacak",
    "Hava serin ama güzel",
    "Bugün hava yağmurlu",
    "Güzel bir gün"
]

tfidf = TfidfVectorizer()
#TfidfVectorizer nesnesinin oluşturulması

X_tfidf = tfidf.fit_transform(metinler)
#metinlerin TF-IDF fromatına dönüşümü

df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns = tfidf.get_feature_names_out())
#oluşan matrisi pandas tablosuna çevirme işlemi

print(df_tfidf)

#Çıktımız vektörel oldu

"""

Özellik                     CountVectorizer              TfidVectorizer

Ne yapar?           Kelimeyi kaç kere geçtiğine   Kelimenin hem sıklığına hem de
                    göre puanlar(sıklık)          metinlerdeki yığınlığına göre puanlar


Her metinde sık    Ağırlığı artar                 Ağırlık düşer(önemsiz sayılır)
geçen kelimeler


Çok geçen ama      Modeli yanıltabilir           Ayıklayıcı etkisi azalır
anlamsız kelimeler

Kullanım Alanı    Küçük veri setleri             Gerçek dünya metinlerinde, metin
                  Kelime var mı/yok mu tarzı     sınıflandırmak daha sağlıklı

Örnek             SMS içeriğinde "ödül" kelimesi  Hangi kelime mesajı spam
                  kaç kere geçiyor?              yapıyor?
"""

#Steowords Temizleme

# "ve", "ile", "bu", "şu","çok"  gibi kelimelerdir

#Genellikle metnin anlamını değiştirmez ama modeli gereksiz
#yere şişirir

#nltk  re(regular expression)--->Metni temizlemek için

import nltk

from nltk.corpus import stopwords#listeyi alacağımız yer

import re # regular expression işlemleri için

nltk.download('stopwords')#ilk defa çlaıştırmada indirir

stop_words=set(stopwords.words('turkish'))#Türkçe için

# Temizlenmemiş örnek cümle listemiz
ham_metinler = [
    "Bugün hava çok güzel.",
    "Yarın yağmur yağacak!",
    "Hava serin ama güzel.",
    "Bugün hava yağmurlu.",
    "Güzel bir gün."
]

temiz_metinler = [] #temizlenmiş metinleri tutacağımız liste

#her cümle için dongu kuracağız
for cumle in ham_metinler:

  cumle = re.sub(r'[^\w\s]', '', cumle.lower())#noktalama kaldır+küçük harf yaz
  #cümleleri küçük harfle yazıma çeviririp noktalama işaretlerini kaldırma

  kelimeler = cumle.split()
  #cümleleri kelimelere ayırıp kelime listesine atama

  anlamli_kelimeler = [kelime for kelime in kelimeler if kelime not in stop_words]

  #stopword dışında kalan kelimeler anlamlıdır bunları alıyoruz

  temiz_cumle = ' '.join(anlamli_kelimeler)
  #temizlenmiş kelimeleri takrar bilreştiriyoruz

  temiz_metinler.append(temiz_cumle)
  #listeye eklenme



print("Temizlenmiş Metinler:")

for cumle in temiz_metinler:
  print("-",cumle)
#sonuçların yazdırılması

#Naive Bayes

"""
Temizlenmiş cümlelerden oluşan bir veri setiyle

     -->Cümlenin pozitif/negatif olduğunu belirlemeyi hedeflemekteyiz

"""


from sklearn.feature_extraction.text import TfidfVectorizer
#metinleri sayıya çevirebilmek için

from sklearn.naive_bayes import MultinomialNB
#Naive Bayes sınıflama için

from sklearn.model_selection import train_test_split
#veri setini eğitim test olarak ayırabilemek için

from sklearn.metrics import accuracy_score,classification_report
#başarı değerlendirme metrikleri

# 1. Temizlenmiş metinleri (özellikle olumlu/olumsuz içerikli) hazırlayalım
veriler = [
    "bu film harikaydı çok beğendim",          # pozitif
    "oyunculuk mükemmeldi ve çok başarılıydı", # pozitif
    "izlediğim en kötü filmdi",                # negatif
    "çok sıkıcıydı zaman kaybı",               # negatif
    "senaryo sürükleyiciydi çok iyiydi",       # pozitif
    "film berbattı hiç beğenmedim",            # negatif
    "müzikler şahane",                         # pozitif
    "hiçbir anlamı yoktu",                     # negatif
]

etiketler = [1,1,0,0,1,0,1,0]
#her cümleye karşılık gelen sınıf etiketleri(1=pozitif, 0=negatif)

tfidf = TfidfVectorizer()
#TF-IDF ile metinleri sayısal vektöre dönüştürme
X = tfidf.fit_transform(veriler)
#Girdi: metinler -->Çıktı : sayısal vektörler

X_train, X_test, y_train, y_test =train_test_split(X, etiketler, test_size=0.2, random_state=42)
#eğitim ve test verileri olarak ikiye ayırma %80'e %20


model=MultinomialNB()
model.fit(X_train, y_train)
#Naive Bayes modelini oluşturma ve eğitme

y_pred = model.predict(X_test)
#test verisi üzerinde tahmin yapma

print("Doğruluk (accuracy):",accuracy_score(y_test, y_pred))
print("\nSınıflandırma Raporu:\n",classification_report(y_test, y_pred))

#veri setin 8 e 2 gibi küçük bir set olunca model dengeli eğitilemediği için
#tahminleri şaşırmış olabilir

!pip install wordcloud

#WordCloud

#Kelime sıklıklarını grafik olarak gösteren bir tekniktir

#Kelime ne kadar büyük görünüyorsa metinlerde o kadar sık geçmiştir.

#Özellikle yorum,haber,tweet gibi verilerde hangi veriler baskın hemen anlaşılır

from wordcloud import WordCloud
#görsselleştirme için

import matplotlib.pyplot as plt
#WordCloud Çiizmi için


# Örnek veri (temizlenmiş cümleler)
temiz_metinler = [
    "film harikaydı çok beğendim",
    "oyunculuk mükemmeldi başarılıydı",
    "izlediğim kötü filmdi",
    "sıkıcıydı zaman kaybı",
    "senaryo sürükleyiciydi iyiydi",
    "film berbattı beğenmedim",
    "müzikler şahane",
    "anlamı yoktu"
]

birlesik_metin = " ".join(temiz_metinler)
#tüm cümlelerin tek string haline getirme

wordcloud = WordCloud(width=800, height=400, background_color='white').generate(birlesik_metin)
#WordCloud nesnesi türeteme

plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')#görüntüleme
plt.axis('off')
plt.title("Kelime Bulutu",fontsize=18)
plt.show()

"""
En Büyük Kelimeler (En Sık Geçenler):
film, beğendim, harikaydı, oyunculuk, mükemmeldi

Bu kelimeler:

Veri setinde olumlu yorumlarda sık geçiyor.

Model için pozitif sınıfı öğrenmede belirleyici olabilir.

Orta Boy Kelimeler:
kötü, sıkıcıydı, berbattı, zaman, beğenmedim

Bu kelimeler ise negatif yorumlarda geçen ayırıcı anahtar kelimeler.

"""